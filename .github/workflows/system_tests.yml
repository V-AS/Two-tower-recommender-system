# .github/workflows/system_tests.yml
name: System Tests with Training

on:
  push:
    branches: [main]
    paths:
      - 'data/processed/recommender_data.csv'  # Trigger on dataset changes
  workflow_dispatch:  # Allow manual triggering

jobs:
  system-test-1:
    runs-on: ubuntu-latest
    outputs:
      validation_result: ${{ steps.validation.outputs.result }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas torch faiss-cpu pytest pytest-cov scikit-learn
      
      # SYSTEM TEST 1: Data Validation
      - name: Run System Test 1 - Dataset Validation
        id: validation
        run: |
          echo "Running System Test 1: Dataset Validation..."
          python tests/system/test_data_validation.py data/processed/recommender_data.csv
          echo "result=success" >> $GITHUB_OUTPUT
        continue-on-error: true
      
      # Create coverage data for later use
      - name: Generate Coverage Data for System Test 1
        if: steps.validation.outputs.result == 'success'
        run: |
          python -m pytest tests/system/test_data_validation.py --cov=src --cov-report=xml:validation-coverage.xml
      
      - name: Upload validation coverage data
        if: steps.validation.outputs.result == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: validation-coverage
          path: validation-coverage.xml
          retention-days: 1

  trigger-training:
    needs: system-test-1
    if: needs.system-test-1.outputs.validation_result == 'success'
    runs-on: ubuntu-latest
    steps:
      # Clear the output directory to ensure we don't detect old files
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Clean output directory
        run: |
          echo "Cleaning output directory to prevent detecting old training files..."
          mkdir -p output
          rm -f output/training_history.json
          rm -f output/user_model.pth
          rm -f output/item_model.pth
          rm -f output/item_embeddings.npy
          rm -f output/ann_index.faiss
          rm -f output/ann_index.meta.npy
          echo "Output directory cleaned."
      
      - name: Trigger training workflow
        uses: peter-evans/repository-dispatch@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          event-type: run-training
          client-payload: '{"ref": "${{ github.ref }}"}'
      
      - name: Wait for training workflow
        run: |
          echo "Triggered training workflow. Please check the 'Model Training' workflow for results."
          echo "System Tests 2 and 3 will run after training completes."

  system-tests-2-3:
    needs: trigger-training
    runs-on: ubuntu-latest
    # This job should only run after the training workflow completes
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install numpy pandas torch faiss-cpu tqdm scikit-learn matplotlib
          pip install pytest pytest-cov coverage
      
      # Wait for training to complete
      - name: Check for training completion
        id: check-training
        run: |
          # Record the start time to compare against file timestamps
          start_time=$(date +%s)
          echo "Workflow start time: $(date -d @$start_time)"
          
          # Create a marker file to know when the training started
          touch .training_started
          
          # Wait for a maximum of 30 minutes (180 x 10 seconds)
          for i in {1..180}; do
            if [ -f "output/training_history.json" ]; then
              # Check if the file was modified after we started waiting
              file_time=$(stat -c %Y "output/training_history.json")
              if [ $file_time -gt $start_time ]; then
                echo "Training completed successfully with a new training_history.json file!"
                echo "training_complete=true" >> $GITHUB_OUTPUT
                break
              else
                echo "Found an old training_history.json file (last modified: $(date -d @$file_time))"
                echo "Continuing to wait for fresh training results..."
              fi
            fi
            echo "Waiting for training to complete... (${i}/180)"
            ls -la output/ || echo "Output directory doesn't exist yet"
            sleep 10
          done
          
          # Check if we have a new training_history.json
          if [ -f "output/training_history.json" ]; then
            file_time=$(stat -c %Y "output/training_history.json")
            if [ $file_time -gt $start_time ]; then
              echo "Found fresh training results"
              exit 0
            else
              echo "Only found outdated training results"
              exit 1
            fi
          else
            echo "Training timed out or failed. No training_history.json found."
            exit 1
          fi
      
      # Download coverage data from validation test
      - name: Download validation coverage
        uses: actions/download-artifact@v4
        with:
          name: validation-coverage
          path: coverage-data/
      
      # SYSTEM TEST 2: Model Convergence
      - name: Run System Test 2 - Model Convergence
        id: convergence
        run: |
          echo "Running System Test 2: Model Convergence..."
          python tests/system/test_model_convergence.py output
      
      # SYSTEM TEST 3: Model Storage
      - name: Run System Test 3 - Model Storage
        id: storage
        if: steps.convergence.outcome == 'success'
        run: |
          echo "Running System Test 3: Model Storage..."
          python tests/system/test_model_storage.py output
      
      # CODE COVERAGE FOR SYSTEM TESTS 2 & 3
      - name: Generate Additional System Tests Coverage
        if: steps.storage.outcome == 'success'
        run: |
          echo "Generating code coverage for remaining system tests..."
          python -m pytest tests/system/test_model_convergence.py tests/system/test_model_storage.py --cov=src --cov-report=xml:tests-coverage.xml
      
      # Merge Coverage Reports
      - name: Merge Coverage Reports
        if: steps.storage.outcome == 'success'
        run: |
          echo "Merging coverage data from all system tests..."
          # Merge the coverage files
          coverage combine coverage-data/validation-coverage.xml tests-coverage.xml
          # Create final reports
          coverage xml -o coverage.xml
          coverage html
      
      - name: Upload XML coverage report
        if: steps.storage.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: system-test-coverage-xml
          path: coverage.xml
          retention-days: 30
      
      - name: Upload HTML coverage report
        if: steps.storage.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: system-test-coverage-html
          path: htmlcov/
          retention-days: 30
      
      - name: Generate coverage summary
        if: steps.storage.outcome == 'success'
        run: |
          echo "## System Test Coverage Summary" > coverage_summary.md
          python -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('coverage.xml')
          root = tree.getroot()
          coverage = root.get('line-rate')
          coverage_pct = float(coverage) * 100
          print(f'Overall coverage: {coverage_pct:.2f}%', file=open('coverage_summary.md', 'a'))
          
          # Print module-level coverage
          print('\n| Module | Coverage |', file=open('coverage_summary.md', 'a'))
          print('|--------|----------|', file=open('coverage_summary.md', 'a'))
          for package in root.findall('.//package'):
              name = package.get('name')
              cov = float(package.get('line-rate')) * 100
              print(f'| {name} | {cov:.2f}% |', file=open('coverage_summary.md', 'a'))
          "
      
      - name: Upload coverage summary
        if: steps.storage.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: system-test-coverage-summary
          path: coverage_summary.md
          retention-days: 30