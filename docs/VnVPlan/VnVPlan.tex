\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}
\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Feb 24, 2025 & 1.0 & First draft - Unit tests will be added after the MIS has been completed..\\
Feb 25, 2025 & 1.1 & Minor update after VnV presentation\\
\bottomrule
\end{tabularx}

~\\

\newpage

\tableofcontents

\listoftables

\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  R & Requirement\\
  NFR & Nonfunctional Requirement\\
  TTE & Two Tower Embedding\\
  RecSys & Recommendation System\\
  ANN & Approximate Nearest Neighbor\\
  SRS & Software Requirements Specification\\
  FAISS & Facebook AI Similarity Search\\
  DNN & Deep Neural Network\\
  \bottomrule
\end{tabular}\\

\newpage

\pagenumbering{arabic}
\nocite{*}
This document outlines the verification and validation plan for the Two-Tower Embeddings Recommendation System (TTE RecSys) to ensure compliance with the requirements and objectives specified in the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{Software Requirements Specification (SRS)}. It is structured to first present general information and verification strategies, followed by detailed descriptions of system and unit testing for both functional and non-functional requirements.

\section{General Information}

\subsection{Summary}

The software under test is the Two-Tower Embedding Recommendation System, which generates personalized recommendations using user and item embeddings. The system consists of two main components:
\begin{itemize}
  \item Training Phase: Learns user and item embedding functions using a deep neural network architecture, optimized via Stochastic Gradient Descent (SGD).
  \item Inference Phase: Retrieves candidate items using Approximate Nearest Neighbor (ANN) search and ranks them by dot product similarity.
\end{itemize}

The system is implemented in Python, leveraging libraries such as PyTorch for model training and FAISS for ANN search.

\subsection{Objectives}
The primary objectives of this VnV plan are:
\begin{itemize}
  \item Correctness: Verify that the system correctly implements the mathematical models for training (e.g., MSE loss) and inference (e.g., ANN search, dot product ranking).
  \item Accuracy: Validate that the system achieves acceptable prediction accuracy on a held-out test set.
  \item Scalability: Demonstrate that the system can support incremental update when new data available.
\end{itemize}
\noindent Out-of-Scope Objectives

\begin{itemize}
  \item External Library Verification: Libraries such as PyTorch and FAISS are assumed to be correct and are not verified as part of this plan.
\end{itemize}

\subsection{Challenge Level and Extras}
This is a non-research project. The extra component of this project will be a user manual.

\subsection{Relevant Documentation}
The following documents are available for this project:
\href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{Software Requirements Specification}, \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftArchitecture/MG.pdf}{Module Guide}, and \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{Module Interface Specification} 

\section{Plan}

The VnV plan starts with an introduction to the verification and validation team, followed by verification plans for the SRS and design. Next, it covers verification plans for the VnV Plan and implementation. Finally, it includes sections on automated testing and verification tools as well as the software validation plan .

\subsection{Verification and Validation Team}\label{VnVT}

\begin{table}[h]
  \centering
  \resizebox{\textwidth}{!}{ %
      \begin{tabular}{ |l|l|p{2cm}|p{5cm}| } 
  \hline        
  
     Name & Document & Role & Description \\
  \hline
    Yinying Huo & All & Author & Prepare all documentation, develop the software, and validate the implementation accoridng to the VnV plan. \\ \hline
    Dr. Spencer Smith & All & Instructor/ Reviewer & Review all the documents.  \\ \hline
    Yuanqi Xue & All & Domain Expert & Review all the documents.  \\ \hline     	  
  \end{tabular} %
  }
  \caption{Verification and Validation Team}
  \label{Table:VnVT}
  \end{table}
  
\subsection{SRS Verification Plan}

The Software Requirements Specification (SRS) will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent There is a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/SRS-Checklist.pdf}{SRS checklist} designed by Dr. Spencer Smith available to use.

\subsection{Design Verification Plan}

The design verification, including the Module Guide (MG) and Module Interface Specification (MIS), will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent Dr. Spencer Smith has created a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/MG-Checklist.pdf}{MG checklist} and \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/MIS-Checklist.pdf}{MIS checklist}, both of which are available for use.

\subsection{Verification and Validation Plan Verification Plan}

The Verification and Validation (VnV) Plan will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent  There is a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/VnV-Checklist.pdf}{VnV checklist} designed by Dr. Spencer Smith available to use.
%

\subsection{Implementation Verification Plan}

The implementation will be verified by testing both the functional and non-functional requirements outlined in section \ref{SystemTest}. Unit tests, as described in section \ref{UnitTest}, will also be performed. Additionally, a code walkthrough will be conducted with the class during the final presentation.

\subsection{Automated Testing and Verification Tools}
All system tests and unit tests will be performed using Python scripts.  
GitHub Actions is used for continuous integration, and the workflow will run all unit tests.
\subsection{Software Validation Plan}

The software validation plan is beyond the scope of \progname, as it requires additional time and data that are not available within the scope of the project.

\section{System Tests}\label{SystemTest}

This section covers the system tests that will be applied to both the functional and non-functional requirements.

\subsection{Tests for Functional Requirements}

The functional requirements are tested in the following areas: input validation, ranking consistency, and output correctness. These tests ensure the system behaves as expected under various conditions.

\subsubsection{Area of Testing 1: Dataset}

\begin{enumerate}

  \item{test-id1\\}
  Control: Automatic\\
  Initial State: Before training the DNN.\\
  Input: Dataset\\
  Output: A verified training dataset where each user-item pair has an associated reward.\\
  Test Case Derivation: Ensures that the system receives a valid dataset for training, as specified in the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{SRS}.

  How test will be performed: This test will be performed automatically using GitHub Actions every time before training the DNN.
					
\end{enumerate}


\subsubsection{Area of Testing 2: Model Training Convergence}

\begin{enumerate}
  \item{test-id2\\}

  Control: Automatic\\
  Initial State: After training of the DNN\\
  Input: The loss record during training\\
  Output: A boolean value, ``True'' if the loss of the DNN decreases over iterations, and ``False'' otherwise.\\
  Test Case Derivation: Ensures the correctness of the output as specified in \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{SRS}.\\
  How the test will be performed: This test will be performed automatically using GitHub Actions once training is complete.

\end{enumerate}

\subsubsection{Area of Testing 3: Model Storage}

\begin{enumerate}
  \item{test-id3:\\}
  
  Control: Automatic\\
  Initial State: After model training is complete\\
  Input: Path to the model and pre-computed item embeddings\\
  Output: bA boolean variable -- ``True'' iif the model and pre-computed item embeddings are stored in the specified location, and ``False'' otherwise\\
  Test Case Derivation: Ensures R3 (model storage) is properly implemented\\
  How test will be performed: The test will be performed automatically using GitHub Actions once model training convergence is complete.
\end{enumerate}


\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Reliability}

The reliability of the software is tested through the tests for
functional requirements in section 4.1 and 5.2 .

\subsubsection{Portability}

\begin{enumerate}

\item{test-id4\\}

Type: Automatic and manual
					
Initial State: None
					
Input/Condition: None
					
Output/Result: The results of all automatic tests and feedback from users.

How test will be performed: All automatic tests will be conducted during the continuous integration workflow. Potential users will install the project on their computers (Windows, macOS, or Linux) and follow the instructions in \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/README.md}{README.md} to run the software. 
\end{enumerate}


\subsubsection{Usability}

\begin{enumerate}

\item{test-id5\\}

Type: Manual

Initial State: The software is setup and ready to use.

Input/Condition: None

Output/Result: Survey result from the user

How test will be performed: The user will be ask to filfiled the servey after using this software. The survey can be find at appendix \ref{US}.


\end{enumerate}

\subsection{Traceability Between Test Cases and Requirements}

The table \ref{Table:S_trace}
 shows the traceability between test cases and requirements

\begin{table}[h!]\label{Table:S_trace}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
  \hline
    & test-id1& test-id2& test-id3&test-id4&test-id5 \\
  \hline
  R1        & X&  & & &  \\ \hline
  R2        & & X& & &  \\ \hline
  R3        & & & X& & \\ \hline
  R4        & & X& & & \\ \hline
  R5        & &X & & & \\ \hline
  R6        & &X & & & X\\ \hline
  NFR1      & & & & &  X\\ \hline
  NFR2      &X & X& X& & \\ \hline
  NFR3      & & & &X & \\ \hline
  \end{tabular}
  \caption{Traceability Matrix Showing the Connections Between Test Cases and Requirements}
  \label{Table:A_trace}
  \end{table}

\section{Unit Test Description}\label{UnitTest}

The unit tests for this system will follow a hierarchical approach based on the module decomposition in the Module Guide. The testing philosophy focuses on:

1. Black-box testing of module interfaces according to their specifications
2. White-box testing for complex algorithms and edge cases
3. Mock objects for isolating modules from their dependencies

\subsection{Unit Testing Scope}
All modules developed for this project will be tested. External libraries (PyTorch, FAISS) are considered outside the scope of unit testing.

\subsection{Tests for Functional Requirements}


\subsubsection{Data Processing Module (M2)}

\begin{enumerate}
  \item{test-M2-1\\}
  Type: Automatic, Functional
            
  Initial State: None
            
  Input: Path to the dataset
            
  Output: Boolean value 'True' indicating the dataset has no missing values
  
  Test Case Derivation: R1 requires the system to accept valid input data.
  
  How test will be performed: Load the dataset using the module and run validation to verify it meets all requirements.
  
\end{enumerate}

\subsubsection{Model Training Module (M3)}

\begin{enumerate}

\item{test-M3-1\\}
Type: Automatic, Functional
					
Initial State: Uninitialized ModelTrainer
					
Input: Valid training configuration
					
Output: ModelTrainer with initialized state (IsInitialized=True)

Test Case Derivation: R2 requires the system to train embedding functions.

How test will be performed: Initialize the ModelTrainer with the configuration and verify the state variables are set correctly.

\end{enumerate}
\subsubsection{Embedding Generation Module (M4)}
\begin{enumerate}

  \item{test-M4-1\\}
  Type: Automatic, Functional
            
  Initial State: Initialized EmbeddingGenerator
            
  Input: A random user data from the dataset
            
  Output: User embedding vector of the expected dimension.
  
  Test Case Derivation: R4 requires the system to generate embeddings based on user features.
  
  How test will be performed: Generate an embedding for an user from the dataset and verify its dimension matches the expected value.
  
  \end{enumerate}

\subsubsection{Recommendation Module (M5)}

\begin{enumerate}

\item{test-M5-1\\}
Type: Automatic, Functional
					
Initial State: Initialized Recommender
					
Input: Processed user data and number of results (10)
					
Output: Array of recommendation objects with length 10, each containing an item ID and similarity score

Test Case Derivation: R6 requires the system to return ranked recommendations with similarity scores.

How test will be performed: Generate recommendations for an user from the dataset and verify the output has the correct format and length.

\end{enumerate}

\subsubsection{Neural Network Architecture Module (M6)}

\begin{enumerate}

\item{test-M6-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Configuration parameters for input dimension, hidden layers, and embedding dimension
					
Output: Neural network model with the specified architecture

Test Case Derivation: R2 requires the system to create models for embedding generation.

How test will be performed: Create a model with the architecture and verify the layer structure matches the specification.

\end{enumerate}
\subsubsection{ANN Search Module (M7)}

\begin{enumerate}

\item{test-M7-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Array of item embeddings from the production model and a query embedding
					
Output: Array of (item\_id, similarity\_score) tuples with the expected length

Test Case Derivation: R6 requires efficient retrieval of nearest items.

How test will be performed: Build an index with item embeddings, search with an user embedding, and verify the results structure. The correctness will not be verified, as the external library (FAISS) is assumed to be correct.

\end{enumerate}

\subsubsection{Vector Operations Module (M8)}

\begin{enumerate}

\item{test-M8-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Two embedding vectors
					
Output: Scalar dot product value

Test Case Derivation: The system relies on dot product for similarity calculation.

How test will be performed: Calculate the dot product of two vectors and compare it with the expected value.

\end{enumerate}


\subsubsection{User Interface Module (M9)}
\begin{enumerate}
  \item test-M9-1\\
  Type: Automatic, Functional\\
  Initial State: Trained models and embeddings exist in output directory\\
  Input: None\\
  Output: Boolean (True/False)\\
  Test Case Derivation: Verify the User Interface can correctly initialize system components\\
  How test will be performed: Function will attempt to initialize system and return True if all components (user model, item model, recommender, embedding generator) are successfully loaded and initialized, False otherwise.
  
\end{enumerate}
\subsection{Tests for Nonfunctional Requirements}

Unit testing the nonfunctional requirements is beyond the scope. 

\subsection{Traceability Between Test Cases and Modules}
The table \ref{Table:Unit} shows the traceability between test cases and modules.


\begin{table}[h!]\label{Table:Unit}
  \centering
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|}
  \hline
  \textbf{Test ID} & \textbf{M1} & \textbf{M2} & \textbf{M3} & \textbf{M4} & \textbf{M5} & \textbf{M6} & \textbf{M7} & \textbf{M8} & \textbf{M9} \\
  \hline
  test-M2-1 &   & X &   &   &   &   &   &   &\\
  test-M3-1 &   &   & X &   &   &   &   &   &\\
  test-M4-1 &   &   &   & X &   &   &   &   &\\
  test-M5-1 &   &   &   &   & X &   &   &   &\\
  test-M6-1 &   &   &   &   &   & X &   &   &\\
  test-M7-1 &   &   &   &   &   &  &  X &   &\\
  test-M8-1 &   &   &   &   &   &   &   & X &\\
  test-M9-1 &   &   &   &   &   &   &   &   & X \\
  \hline
  \end{tabular}
  \caption{Traceability Matrix Between Test Cases and Modules}
  \end{table}

  \bibliographystyle {plainnat}
  \bibliography {../../refs/References}

\newpage
\section{Appendix}


\subsection{Usability Survey}\label{US}
\begin{itemize}
\item On a scale from 1 to 5, with 5 being the most satisfied, how would you rate your overall experience using the software?
\item Were the installation and setup process straightforward? If not, what difficulties did you encounter?
\item Did you find the user interface intuitive and easy to navigate? If not, what improvements would you suggest?
\item Did the software meet your expectations? If not, what features or improvements would you like to see?
\end{itemize}

\end{document}