\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{System Verification and Validation Plan for \progname{}} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Feb 24, 2025 & 1.0 & First draft - Unit tests will be added after the MIS has been completed..\\
Feb 25, 2025 & 1.1 & Minor update after VnV presentation\\
\bottomrule
\end{tabularx}

~\\

\newpage

\tableofcontents

\listoftables

\newpage

\section{Symbols, Abbreviations, and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  R & Requirement\\
  NFR & Nonfunctional Requirement\\
  TTE & Two Tower Embedding\\
  RecSys & Recommendation System\\
  ANN & Approximate Nearest Neighbor\\
  SRS & Software Requirements Specification\\
  FAISS & Facebook AI Similarity Search\\

  \bottomrule
\end{tabular}\\

\newpage

\pagenumbering{arabic}

This document outlines the verification and validation plan for the Two-Tower Embeddings Recommendation System (TTE RecSys) to ensure compliance with the requirements and objectives specified in the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{Software Requirements Specification (SRS)}. It is structured to first present general information and verification strategies, followed by detailed descriptions of system and unit testing for both functional and non-functional requirements.

\section{General Information}

\subsection{Summary}

The software under test is the Two-Tower Embedding Recommendation System, which generates personalized recommendations using user and item embeddings. The system consists of two main components:
\begin{itemize}
  \item Training Phase: Learns user and item embedding functions using a deep neural network architecture, optimized via Stochastic Gradient Descent (SGD).
  \item Inference Phase: Retrieves candidate items using Approximate Nearest Neighbor (ANN) search and ranks them by dot product similarity.
\end{itemize}

The system is implemented in Python, leveraging libraries such as PyTorch for model training and FAISS for ANN search.

\subsection{Objectives}
The primary objectives of this VnV plan are:
\begin{itemize}
  \item Correctness: Verify that the system correctly implements the mathematical models for training (e.g., MSE loss) and inference (e.g., ANN search, dot product ranking).
  \item Accuracy: Validate that the system achieves acceptable prediction accuracy on a held-out test set.
  \item Scalability: Demonstrate that the system can support incremental update when new data available.
\end{itemize}
\noindent Out-of-Scope Objectives

\begin{itemize}
  \item External Library Verification: Libraries such as PyTorch and FAISS are assumed to be correct and are not verified as part of this plan.
\end{itemize}

\subsection{Challenge Level and Extras}
This is a non-research project. The extra component of this project will be a user manual.

\subsection{Relevant Documentation}
The following documents are available for this project:
\href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{Software Requirements Specification}, \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftArchitecture/MG.pdf}{Module Guide}, and \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{Module Interface Specification} 

\section{Plan}

The VnV plan starts with an introduction to the verification and validation team, followed by verification plans for the SRS and design. Next, it covers verification plans for the VnV Plan and implementation. Finally, it includes sections on automated testing and verification tools as well as the software validation plan .

\subsection{Verification and Validation Team}\label{VnVT}

\begin{table}[h]
  \centering
  \resizebox{\textwidth}{!}{ %
      \begin{tabular}{ |l|l|p{2cm}|p{5cm}| } 
  \hline        
  
     Name & Document & Role & Description \\
  \hline
    Yinying Huo & All & Author & Prepare all documentation, develop the software, and validate the implementation accoridng to the VnV plan. \\ \hline
    Dr. Spencer Smith & All & Instructor/ Reviewer & Review all the documents.  \\ \hline
    Yuanqi Xue & All & Domain Expert & Review all the documents.  \\ \hline     	  
  \end{tabular} %
  }
  \caption{Verification and Validation Team}
  \label{Table:VnVT}
  \end{table}
  
\subsection{SRS Verification Plan}

The Software Requirements Specification (SRS) will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent There is a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/SRS-Checklist.pdf}{SRS checklist} designed by Dr. Spencer Smith available to use.

\subsection{Design Verification Plan}

The design verification, including the Module Guide (MG) and Module Interface Specification (MIS), will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent Dr. Spencer Smith has created a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/MG-Checklist.pdf}{MG checklist} and \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/MIS-Checklist.pdf}{MIS checklist}, both of which are available for use.

\subsection{Verification and Validation Plan Verification Plan}

The Verification and Validation (VnV) Plan will be reviewed by domain expert Yuanqi Xue and Dr. Smith. Feedback from reviewers will be provided on GitHub, and the author will need to address it.

\noindent  There is a \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Checklists/VnV-Checklist.pdf}{VnV checklist} designed by Dr. Spencer Smith available to use.
%

\subsection{Implementation Verification Plan}

The implementation will be verified by testing both the functional and non-functional requirements outlined in section \ref{SystemTest}. Unit tests, as described in section \ref{UnitTest}, will also be performed. Additionally, a code walkthrough will be conducted with the class during the final presentation.

\subsection{Automated Testing and Verification Tools}
The following tools will be used for automated testing and verification:
\begin{itemize}
\item \textbf{Unit Testing}:
\begin{itemize}
\item \textbf{Pytest}: For testing individual components (e.g., embedding functions, ANN search, ranking logic).
\end{itemize}
\item \textbf{Continuous Integration (CI)}:
\begin{itemize}
\item \textbf{GitHub Actions}: Automates all unit tests, some system tests, and deployment workflows.
\item \textbf{CML (Continuous Machine Learning)}: Automatically generates performance reports and emails metrics when changes are pushed to GitHub.
\item The CI workflow will run all unit tests.
\end{itemize}
\end{itemize}

\subsection{Software Validation Plan}

The software validation plan is beyond the scope of \progname, as it requires additional time and data that are not available within the scope of the project.

\section{System Tests}\label{SystemTest}

This section covers the system tests that will be applied to both the functional and non-functional requirements.

\subsection{Tests for Functional Requirements}

The functional requirements are tested in the following areas: input validation, ranking consistency, and output correctness. These tests ensure the system behaves as expected under various conditions.

\subsubsection{Area of Testing 1: Dataset}

\begin{enumerate}

  \item{test-id1\\}
  Control: Automatic\\
  Initial State: Before training the embedding functions.\\
  Input: Dataset\\
  Output: A verified dataset where each user-item pair in the verified dataset has an associated reward and no missing values.\\
  Test Case Derivation: Ensures that the system handles valid inputs as specified in the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{SRS}, which also includes the training dataset used for this project.

  How test will be performed: Automated test using GitHub Actions.
					
\end{enumerate}


\subsubsection{Test for performance}

\begin{enumerate}
  \item{test-id2\\}

  Control: Automatic\\
  Initial State: After training of the embedding functions\\
  Input: The testing dataset and embedding functions\\
  Output: The performance of the user embedding and item embedding functions is acceptable (accuracy $>$ 80\%)\\
  Test Case Derivation: Ensures the correctness of the output as specified in \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{SRS}.\\
  How the test will be performed: This test will be performed automatically using GitHub Actions once the training is finished.

\item{test-id3\\}

Control: Automatic\\
Initial State: System initialized with pre-computed item embeddings and trained ANN index.\\
Input:  user embeddings\\
Output: The ranking for the top 5 items should generally be the same for identical user embeddings. Non-consistent rankings are allowed (up to 5\%) due to the inherent randomness in machine learning.\\
Test Case Derivation: Ensures that identical user embeddings produce identical item rankings, as stated in \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/SRS/SRS.pdf}{SRS}.\\
How the test will be performed: This test will be performed automatically using GitHub Actions. It will generate 100 lists of recommended items for a random user.\\

\end{enumerate}

\subsubsection{Area of Testing 3: Model Storage}

\begin{enumerate}
  \item{test-id4:\\}
  
  Control: Automatic\\
  Initial State: After model training is complete\\
  Input: Trained model to be saved\\
  Output: Model successfully stored and can be retrieved with identical parameters\\
Test Case Derivation: Ensures R3 (model storage) is properly implemented
How test will be performed: Automated test that saves the model, loads it back, and verifies parameter integrity
\end{enumerate}


\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Reliability}

The reliability of the software is tested through the tests for
functional requirements in section 4.1 and 5.2 .

\subsubsection{Portability}

\begin{enumerate}

\item{test-id5\\}

Type: Manual
					
Initial State: None
					
Input/Condition: None
					
Output/Result: The project should pass all the tests for functional requirements and run without any errors.

How test will be performed: Potential users will install the project on their computers (Windows, macOS, or Linux) and execute a sample workflow. 
\end{enumerate}


\subsubsection{Scalability}

\begin{enumerate}

\item{test-id6\\}

Type: Manual

Initial State: System initialized with a model trained on 70\% of the dataset.

Input/Condition: Remaining 30\% of the dataset added as new data.

Output/Result: Model updates complete within 1 minute.

How test will be performed: Because there is no external data for updates, the system will first train the model on 70\% of the training set. After training is done and all the functional requirements have passed, the remaining 30\% will be added as new data to simulate incremental updates.


\end{enumerate}

\subsection{Traceability Between Test Cases and Requirements}

The table \ref{Table:S_trace}
 shows the traceability between test cases and requirements

\begin{table}[h!]\label{Table:S_trace}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
  \hline
    & test-id1& test-id2& test-id3&test-id4&test-id5&test-id6 \\
  \hline
  R1        & X&  & & & & \\ \hline
  R2        & & X& & & & \\ \hline
  R3        & & & &X& &\\ \hline
  R4        & & & X& & &\\ \hline
  R5        & &X & X& & &\\ \hline
  R6        & &X & X& & &\\ \hline
  NFR1      & & & & & &X\\ \hline
  NFR2      &X & X& X& X& &\\ \hline
  NFR3      & & & & &X&\\ \hline
  \end{tabular}
  \caption{Traceability Matrix Showing the Connections Between Test Cases and Requirements}
  \label{Table:A_trace}
  \end{table}

\section{Unit Test Description}\label{UnitTest}

The unit tests for this system will follow a hierarchical approach based on the module decomposition in the Module Guide. The testing philosophy focuses on:

1. Black-box testing of module interfaces according to their specifications
2. White-box testing for complex algorithms and edge cases
3. Mock objects for isolating modules from their dependencies

\subsection{Unit Testing Scope}
All modules developed for this project will be tested. External libraries (PyTorch, FAISS) are considered outside the scope of unit testing.

\subsection{Tests for Functional Requirements}

\subsubsection{System Interface Module (M1)}

\begin{enumerate}

  \item{test-M1-1\\}
Type: Automatic, Functional
					
Initial State: File system with sufficient storage space

Input: Trained model object
					
Output: Boolean value 'True' indicating successful save and load operation

Test Case Derivation: R3 requires the system to store and retrieve trained embedding functions.

How test will be performed: Use the fully trained production model, save it to disk, load it back, and verify the model parameters are preserved.


\end{enumerate}

\subsubsection{Data Processing Module (M2)}

\begin{enumerate}
  \item{test-M2-1\\}
  Type: Automatic, Functional
            
  Initial State: None
            
  Input: Path to the production dataset file
            
  Output: Boolean value 'True' indicating the dataset has no missing values and meets all validation criteria
  
  Test Case Derivation: R1 requires the system to accept valid input data.
  
  How test will be performed: Load the production dataset using the module and run validation to verify it meets all requirements.
  
\end{enumerate}

\subsubsection{Model Training Module (M3)}

\begin{enumerate}

\item{test-M3-1\\}
Type: Automatic, Functional
					
Initial State: Uninitialized ModelTrainer
					
Input: Valid training configuration
					
Output: ModelTrainer with initialized state (IsInitialized=True)

Test Case Derivation: R2 requires the system to train embedding functions.

How test will be performed: Initialize the ModelTrainer with the configuration and verify the state variables are set correctly.

\end{enumerate}
\subsubsection{Embedding Generation Module (M4)}
\begin{enumerate}

  \item{test-M4-1\\}
  Type: Automatic, Functional
            
  Initial State: Initialized EmbeddingGenerator
            
  Input: A random user data from the dataset
            
  Output: User embedding vector of the expected dimension.
  
  Test Case Derivation: R4 requires the system to generate embeddings based on user features.
  
  How test will be performed: Generate an embedding for an user from the dataset and verify its dimension matches the expected value.
  
  \end{enumerate}

\subsubsection{Recommendation Module (M5)}

\begin{enumerate}

\item{test-M5-1\\}
Type: Automatic, Functional
					
Initial State: Initialized Recommender
					
Input: Processed user data and number of results (10)
					
Output: Array of recommendation objects with length 10, each containing an item ID and similarity score

Test Case Derivation: R6 requires the system to return ranked recommendations with similarity scores.

How test will be performed: Generate recommendations for an user from the dataset and verify the output has the correct format and length.

\end{enumerate}

\subsubsection{Neural Network Architecture Module (M6)}

\begin{enumerate}

\item{test-M6-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Configuration parameters for input dimension, hidden layers, and embedding dimension
					
Output: Neural network model with the specified architecture

Test Case Derivation: R2 requires the system to create models for embedding generation.

How test will be performed: Create a model with the architecture and verify the layer structure matches the specification.

\end{enumerate}
\subsubsection{ANN Search Module (M7)}

\begin{enumerate}

\item{test-M7-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Array of item embeddings from the production model and a query embedding
					
Output: Array of (item\_id, similarity\_score) tuples with the expected length

Test Case Derivation: R6 requires efficient retrieval of nearest items.

How test will be performed: Build an index with item embeddings, search with an user embedding, and verify the results structure. The correctness will not be verified, as the external library (FAISS) is assumed to be correct.

\end{enumerate}

\subsubsection{Vector Operations Module (M8)}

\begin{enumerate}

\item{test-M8-1\\}
Type: Automatic, Functional
					
Initial State: None
					
Input: Two embedding vectors
					
Output: Scalar dot product value

Test Case Derivation: The system relies on dot product for similarity calculation.

How test will be performed: Calculate the dot product of two actual embedding vectors from the model and verify the result is a scalar value.

\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}


\subsubsection{Scalability Test}

\begin{enumerate}

\item{test-NFR1-1\\}
Type: Automatic, Performance
					
Initial State: Trained model
					
Input: New data
					
Output: An updated model

Test Case Derivation: NFR1 requires incremental updates when new data becomes available.

How test will be performed: Add new data to the existing model and verify the model parameters have been updated correctly.
\end{enumerate}

\subsubsection{Portability Test}

\begin{enumerate}

\item{test-NFR3-1\\}
Type: Manual, Compatibility
					
Initial State: Complete system package
					
Input: Installation commands on different platforms
					
Output: System runs successfully on Windows, Linux, and macOS

Test Case Derivation: NFR3 requires operation on multiple platforms.

How test will be performed: Install and run the system on each platform, performing a standard recommendation operation.

\end{enumerate}

\subsection{Traceability Between Test Cases and Modules}
The table \ref{Table:Unit} shows the traceability between test cases and modules.


\begin{table}[h!]\label{Table:Unit}
  \centering
  \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
  \hline
  \textbf{Test ID} & \textbf{M1} & \textbf{M2} & \textbf{M3} & \textbf{M4} & \textbf{M5} & \textbf{M6} & \textbf{M7} & \textbf{M8} \\
  \hline
  test-M1-1 & X &   &   &   &   &   &   &   \\
  test-M2-1 &   & X &   &   &   &   &   &   \\
  test-M3-1 &   &   & X &   &   &   &   &   \\
  test-M4-1 &   &   &   & X &   &   &   &   \\
  test-M5-1 &   &   &   &   & X &   &   &   \\
  test-M6-1 &   &   &   &   &   & X &   &   \\
  test-M7-1 &   &   &   &   &   &  &  X &   \\
  test-M8-1 &   &   &   &   &   &   &   & X \\
  \hline
  test-NFR1-1 &   &   & X &   &   &   &   &   \\
  test-NFR3-1 & X & X & X & X & X & X & X & X \\
  \hline
  \end{tabular}
  \caption{Traceability Matrix Between Test Cases and Modules}
  \end{table}
				
\bibliographystyle{plainnat}

\bibliography{../../refs/References}

\end{document}