\documentclass[12pt, a4paper, oneside]{book}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{enumitem}
\nocite{*}
\geometry{a4paper, margin=1in}

% Define colors
\definecolor{codebackground}{rgb}{0.95,0.95,0.95}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{darkgreen}{rgb}{0.0,0.5,0.0}
\definecolor{darkred}{rgb}{0.5,0.0,0.0}

% Define code listing style
\lstset{
    backgroundcolor=\color{codebackground},
    basicstyle=\footnotesize\ttfamily,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    commentstyle=\color{darkgreen},
    keywordstyle=\color{darkblue},
    stringstyle=\color{darkred},
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    rulecolor=\color{black},
    rulesepcolor=\color{black}
}

% Set page headers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\textit{Two-Tower Recommendation System}}
\fancyhead[LO]{\textit{\leftmark}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

\title{
    \textbf{Two-Tower Recommendation System}\\
    \large User Manual
}
\author{Yinying Huo}
\date{April 2025}

\begin{document}

\frontmatter
\maketitle

\tableofcontents

\chapter*{Preface}
\addcontentsline{toc}{chapter}{Preface}

This user manual provides comprehensive instructions for installing, configuring, and using the Two-Tower Recommendation System. This system is designed to provide personalized book recommendations based on user profiles using a deep learning approach.

The Two-Tower Embedding (TTE) architecture maps users and items into a shared embedding space, enabling efficient and accurate recommendation generation.

This document is intended for both end-users who want to use the recommendation system and developers who may want to extend or modify its functionality.

\mainmatter

\chapter{Introduction}

\section{System Overview}
The Two-Tower Recommendation System is a machine learning-based recommendation engine that suggests books to users based on their profile information and the characteristics of available books. The system uses a neural network architecture known as "Two-Tower Embedding" (TTE) to map both users and books into a shared embedding space. Recommendations are generated by finding books whose embeddings are closest to the user embedding in this space.

\section{Key Features}
\begin{itemize}
    \item Deep learning-based recommendation system using PyTorch
    \item Highly efficient ANN (Approximate Nearest Neighbor) search using FAISS
    \item Personalized book recommendations based on user age, location, and other features
    \item Extensible architecture allowing for easy updates and modifications
    \item Command-line interface for easy interaction
    \item Fast inference time even with large book catalogs
\end{itemize}

\section{Architecture}
The system is based on a modular architecture that follows the principle of information hiding. It consists of three main layers:

\begin{enumerate}
    \item \textbf{Hardware-Hiding Module}: Handles system interactions like file I/O
    \item \textbf{Behavior-Hiding Modules}: Implement the core functionality
        \begin{itemize}
            \item System Interface Module
            \item Data Processing Module
            \item Model Training Module
            \item Embedding Generation Module
            \item Recommendation Module
        \end{itemize}
    \item \textbf{Software Decision Modules}: Implement algorithm-specific functionality
        \begin{itemize}
            \item Neural Network Architecture Module
            \item ANN Search Module
            \item Vector Operations Module
        \end{itemize}
\end{enumerate}


\chapter{Installation}

\section{Prerequisites}
Before installing the Two-Tower Recommendation System, ensure your system meets the following requirements:

\begin{itemize}
    \item Python 3.9 or higher
    \item PyTorch 1.9 or higher
    \item FAISS for vector similarity search
    \item Other dependencies as listed in \texttt{requirements.txt}
\end{itemize}

\section{Installation Steps}

\begin{enumerate}
    \item Clone the repository:
    
    \begin{lstlisting}[language=bash]
git clone https://github.com/V-AS/Two-tower-recommender-system.git
cd Two-tower-recommender-system
    \end{lstlisting}
    
    \item Create and activate a virtual environment:
    
    \begin{lstlisting}[language=bash]
python3 -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
    \end{lstlisting}
    
    \item Install dependencies:
    
    \begin{lstlisting}[language=bash]
pip install -r requirements.txt
    \end{lstlisting}
    
    \item Install FAISS:
    
    \begin{lstlisting}[language=bash]
# For CPU-only systems:
pip install faiss-cpu

# For systems with NVIDIA GPU:
pip install faiss-gpu
    \end{lstlisting}
\end{enumerate}


\chapter{Data Requirements and Processing}

\section{Data Format}
The system expects data in a specific format to train the recommendation model. The required data consists of:

\begin{itemize}
    \item \textbf{User information}: Including age, location
    \item \textbf{Book information}: Including title, author, publication year, publisher
    \item \textbf{Ratings}: Mapping users to books with numerical ratings
\end{itemize}

The system expects a CSV file with the following columns:
\begin{itemize}
    \item User-ID
    \item Book-Rating
    \item Book-Title
    \item Book-Author
    \item Year-Of-Publication
    \item Publisher
    \item Age
    \item State
    \item Country
\end{itemize}

\section{Data Processing}
The system includes a data processing module that performs several important transformations:

\begin{enumerate}
    \item \textbf{Data validation}: Checks if all required columns are present
    \item \textbf{Feature engineering}: Creates derived features such as:
        \begin{itemize}
            \item Age groups
            \item State and country frequency
            \item Author and publisher frequency
        \end{itemize}
    \item \textbf{Missing value handling}: Imputes missing values with sensible defaults
    \item \textbf{Data splitting}: Divides data into training and testing sets
\end{enumerate}

If you need to preprocess your own data, the repository includes a Jupyter notebook in \texttt{src/utils/data\_preprocessing.ipynb} that demonstrates how to merge separate user, book, and rating files into the required format.

\chapter{Usage Instructions}

\section{Quick Start}
For users who want to immediately start getting recommendations, the system includes pre-trained models in the \texttt{output} folder. You can start the user interface with:

\begin{lstlisting}[language=bash]
python src/user_interface.py
\end{lstlisting}

This will launch an interactive terminal where you can enter your information (age, state, country) to get personalized book recommendations.

For debugging information, use:

\begin{lstlisting}[language=bash]
python src/user_interface.py --debug
\end{lstlisting}

\section{Using the User Interface}
The user interface provides a simple way to interact with the recommendation system:

\begin{enumerate}
    \item When launched, the system will display the top states/countries in the dataset
    \item Enter your age when prompted
    \item Enter your state/province (or press Enter for "Unknown")
    \item Enter your country (or press Enter for "Unknown")
    \item Wait for recommendations to be generated
    \item View your personalized book recommendations
    \item Choose whether to get more recommendations
\end{enumerate}

\begin{tcolorbox}[title=Example Session]
\begin{verbatim}
$ python src/user_interface.py

====================
TOP 10 STATES/PROVINCES IN THE DATASET
--------------------
1. california: 8521 users (12.5%)
2. new york: 7234 users (10.6%)
3. texas: 4521 users (6.6%)
...

====================
TOP 10 COUNTRIES IN THE DATASET
--------------------
1. usa: 52341 users (76.8%)
2. canada: 5234 users (7.7%)
3. united kingdom: 4523 users (6.6%)
...

====================
BOOK RECOMMENDATION SYSTEM
====================

Please enter your information to get personalized book recommendations:
Your age (0-100): 32
...
\end{verbatim}
\end{tcolorbox}

\section{Command-Line Arguments}
The user interface supports the following command-line arguments:

\begin{itemize}
    \item \texttt{--age}: Your age (e.g., \texttt{--age 32})
    \item \texttt{--state}: Your state or province (e.g., \texttt{--state california})
    \item \texttt{--country}: Your country (e.g., \texttt{--country usa})
    \item \texttt{--debug}: Enable debug mode for additional information
\end{itemize}

If you provide the age, state, and country arguments, the system will generate recommendations without prompting for additional input.

\section{Training the Model}
If you want to train the model from scratch or on your own data, you can use the \texttt{main.py} script:

\begin{lstlisting}[language=bash]
python src/main.py --mode train --epochs 3 --batch_size 10 --embedding_dim 32
\end{lstlisting}

The training process takes approximately 5 minutes with the recommended parameters, which have been optimized for the default dataset.

The training process involves:
\begin{enumerate}
    \item Loading and preprocessing the data
    \item Creating neural network architectures for the user and item towers
    \item Training the model to predict ratings
    \item Evaluating the model on a test set
    \item Generating and saving embeddings
    \item Building and saving an ANN index
\end{enumerate}

\section{Getting Recommendations for a Specific User}
You can generate recommendations for a specific user ID using:

\begin{lstlisting}[language=bash]
python src/main.py --mode recommend --user_id 12345 --num_recommendations 10
\end{lstlisting}

This will look up the user in the dataset, generate their embedding, and return personalized recommendations.

\chapter{Advanced Usage}

\section{Model Parameters}
The system offers several configurable parameters for model training:

\begin{tabular}{p{4cm}p{5cm}p{4cm}}
\toprule
Parameter & Description & Default Value \\
\midrule
\texttt{--epochs} & Number of training epochs & 5 \\
\texttt{--batch\_size} & Training batch size & 10 \\
\texttt{--embedding\_dim} & Dimension of embedding vectors & 32 \\
\texttt{--data\_path} & Path to training data & \texttt{data/processed/recommender\_data.csv} \\
\texttt{--output\_dir} & Directory to save models & \texttt{output} \\
\texttt{--num\_recommendations} & Number of recommendations to generate & 10 \\
\bottomrule
\end{tabular}

\section{Customizing Neural Network Architecture}
The neural network architecture can be customized by modifying the \texttt{src/modules/neural\_network.py} file. The default implementation uses a simple tower with one hidden layer, but you can add more layers or change activation functions as needed.

\section{Optimizing FAISS Index}
The FAISS index type can be modified in \texttt{src/modules/ann\_search.py}. The default implementation uses a flat index, which provides exact search results but may be slower with very large datasets. For larger datasets, consider using IVF indices which trade some accuracy for significant speed improvements.

\chapter{System Components}

The system design is described in detail in two documents: the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftArchitecture/MG.pdf}{Module Guide} and the \href{https://github.com/V-AS/Two-tower-recommender-system/blob/main/docs/Design/SoftDetailedDes/MIS.pdf}{Module Interface Specification}.

\chapter{Troubleshooting}

\section{Common Issues}
\begin{description}
    \item[Issue: \texttt{ImportError: No module named 'faiss'}]\ \\
    \textbf{Solution:} Make sure you have installed FAISS correctly for your system.
    \begin{lstlisting}[language=bash]
# For CPU-only systems:
pip install faiss-cpu

# For systems with NVIDIA GPU:
pip install faiss-gpu
    \end{lstlisting}

    \item[Issue: \texttt{CUDA out of memory}]\ \\
    \textbf{Solution:} Try reducing the batch size or embedding dimension.
    \begin{lstlisting}[language=bash]
python src/main.py --mode train --batch_size 4 --embedding_dim 16
    \end{lstlisting}

    \item[Issue: \texttt{File not found: data/processed/recommender\_data.csv}]\ \\
    \textbf{Solution:} Make sure you're running the script from the project root directory, or specify the full path to the data file.
    \begin{lstlisting}[language=bash]
python src/main.py --data_path /full/path/to/data/processed/recommender_data.csv
    \end{lstlisting}

\end{description}

\section{Debugging Tips}
\begin{enumerate}
    \item Enable debug mode when running the user interface:
    \begin{lstlisting}[language=bash]
python src/user_interface.py --debug
    \end{lstlisting}

    \item Check the training history in \texttt{output/training\_history.json} to see if the model is learning properly.

    \item Run a specific test file to check if a particular component is working as expected:
    \begin{lstlisting}[language=bash]
pytest tests/unit/test_embedding_generation.py
    \end{lstlisting}
\end{enumerate}

\appendix

\chapter{Glossary}

\begin{description}
    \item[ANN (Approximate Nearest Neighbor)] A technique for finding similar vectors in high-dimensional space, which trades some accuracy for improved speed and memory usage.
    
    \item[Embedding] A low-dimensional, dense vector representation of a high-dimensional, sparse feature. In this system, both users and items are represented as embeddings in a shared vector space.
    
    \item[FAISS] Facebook AI Similarity Search, a library for efficient similarity search and clustering of dense vectors.
    
    \item[Two-Tower Architecture] A neural network architecture with two parallel networks (towers) that process different types of inputs (users and items) and map them to a shared embedding space.
    
    \item[Feature Engineering] The process of creating new features from raw data to improve model performance.
    
    \item[Dot Product] A vector operation that calculates the sum of the products of corresponding elements. Used to calculate similarity between embeddings.
    
    \item[Normalization] The process of scaling values to a standard range, typically [0, 1].
    
\end{description}

\backmatter

\end{document}